# -*- coding: utf-8 -*-
"""Modelos de machine learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ypu7nkApNCz5SexqydwyG3qvC1FVTD3H
"""

# Bibliotecas utilizadas
import pandas as pd
import numpy as np
import seaborn as sns
import graphviz
import matplotlib.pyplot as plt
from sklearn import tree, metrics
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

# Upload do arquivo
from google.colab import files
uploaded = files.upload()

# Leitura do arquivo:
df = pd.read_csv('titanic.csv')
df.head()

# Descrição dos dados
df.describe()

# Output com informações sobre os dados:
df.info()

# Substituição da variável “Sex” por 1 e 0.
df['Sex Category'] = df['Sex']
df['Sex Category'].replace(['female', 'male'], [0,1], inplace=True)
df['Sex Category'].value_counts()

# desvio padrão da variável “Age”
df['Age'].std()

# Categorização da variável “Age”, o desvio padrão é 14.12, arredondamos para 16 e separamos em categorias de 16 em 16.
df['Age Category'] = pd.cut(df['Age'], bins=[0,16,32,48,64,80], labels=[0,1,2,3,4])
df['Age Category'].value_counts(sort=False)

# quartis  da variável “Fare”
df['Fare'].quantile([0.25, 0.5, 0.75])

# Categorização da variável “Fare”, separamos pelos quartis, 7.92, 14.45 e 31.13.
df['Fare Category'] = pd.cut(df['Fare'],bins=[-np.inf,7.92,14.45,31.13,np.inf], labels=[0,1,2,3])
df['Fare Category'].value_counts(sort=False)

# Criação da variável “Family”, somando as variáveis “Siblings/Spouses Aboard” e “Parents/Children Aboard”.
df['Family'] = df['Siblings/Spouses Aboard'] + df['Parents/Children Aboard']
df['Family'].value_counts(sort=False)

# Categorização da variável “Family”, utilizando 1 para qualquer quantidade e 0 para nenhum.
df['Family Category'] = df['Family'].apply(lambda x: 1 if x > 0 else 0)
df['Family Category'].value_counts()

# Separação da base com os dados que serão utilizados.
data = df[['Pclass', 'Sex Category', 'Age Category', 'Fare Category', 'Family Category']]
data.columns = ['Pclass', 'Sex', 'Age', 'Fare', 'Family']
data

# Variável target
target = df['Survived']
target

# Separação da base em treino e teste utilizando o train_test_split, foi utilizado o seed (random_state=41) para que o script retorne os mesmos dados quando reproduzido
train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=41)
print('base de treino: ', len(train_data))
print('base de teste: ', len(test_data))

# Criação da árvore de decisão com a base de treino:
clf = tree.DecisionTreeClassifier()
clf.fit(train_data, train_target)

# Exibição do gráfico árvore de decisão, como a árvore ficou muito complexa, vamos limitar a 3 níveis para visualização:
graph_data = tree.export_graphviz(clf, out_file=None,
                                  feature_names=data.columns,  
                                  class_names=['morreu', 'sobreviveu'],  
                                  filled=True, rounded=True, max_depth=3)

graph = graphviz.Source(graph_data) 
graph

# Predição
predicted = clf.predict(test_data)
predicted

# Medindo a acurácia da predição
acuracia = metrics.accuracy_score(test_target, predicted)
print("Acurácia: %.2f%%\n" % (acuracia*100))

# Testando a árvore de decisão 1.000 vezes, com diferentes separações de base de treino e de teste. 
acuracias = []

for i in range(1000):
  train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.4)
  clf.fit(train_data, train_target)
  predicted = clf.predict(test_data)
  acuracias.append(metrics.accuracy_score(test_target, predicted))

print("Acurácia: %.2f%%\n" % (np.mean(acuracias)*100))

# Random Forest
rfc = RandomForestClassifier(n_estimators=1000)
rfc.fit(train_data, train_target)

# Predição
predicted = rfc.predict(test_data)
predicted

# Medindo a acurácia da predição
acuracia = metrics.accuracy_score(test_target, predicted)
print("Acurácia: %.2f%%\n" % (acuracia*100))

# KNN - K-Nearest Neighbors:
knn = KNeighborsClassifier()
knn.fit(train_data, train_target)

# Predição
predicted = knn.predict(test_data)
predicted

# Medindo a acurácia da predição
acuracia = metrics.accuracy_score(test_target, predicted)
print("Acurácia: %.2f%%\n" % (acuracia*100))

kscores = range(1, 30)
scores = []

for k in kscores:
  knn = KNeighborsClassifier(n_neighbors=k)
  knn.fit(train_data, train_target)
  predicted = knn.predict(test_data)
  score = metrics.accuracy_score(test_target, predicted)
  scores.append(score)

plt.plot(kscores, scores)
plt.xlabel("Valor de K")
plt.ylabel("Acurácia")

# Testando a árvore de decisão 1.000 vezes, com diferentes separações de base de treino e de teste. 
acuracias = []

knn = KNeighborsClassifier(n_neighbors=5)

for i in range(1000):
  train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.2)
  knn.fit(train_data, train_target)
  predicted = knn.predict(test_data)
  acuracias.append(metrics.accuracy_score(test_target, predicted))

print("Acurácia: %.2f%%\n" % (np.mean(acuracias)*100))