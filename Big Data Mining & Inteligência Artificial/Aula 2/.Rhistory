install.packages('devtools')
install.packages('devtools')
install.packages('evaluate')
install.packages('devtools')
install.packages('devtools')
install.packages('devtools')
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages('devtools')
install.packages('devtools')
exit
install.packages('devtools')
install.packages('devtools')
install.packages("devtools")
install.packages('evaluate')
install.packages('digest')
install.packages('highr')
install.packages('markdown')
install.packages('stringi')
install.packages('stringr')
install.packages('yaml')
install.packages('Rcpp')
install.packages('htmltools')
install.packages('caTools')
install.packages('bitops')
install.packages('knitr')
install.packages('jsonlite')
install.packages('base64enc')
install.packages('rprojroot')
install.packages('rmarkdown')
install.packages('shiny')
install.packages('dplyr')
install.packages('tidyr')
install.packages('ggplot2')
install.packages('plotly')
install.packages('sqldf')
install.packages('ape')
install.packages('zoo')
install.packages('caret')
install.packages("swirl"
install.packages("swirlify"
install.packages('RCurl')
install.packages('RJSONIO')
install.packages('PKI')
install.packages('rstudioapi')
install.packages('packrat')
install.packages('rsconnect')
install.packages(c("janeaustenr", "tidytext", "tidyverse", "wordcloud"))
## FIAP - 1S2020
## Data mining
## Prof. André Insardi
## (adaptado de material de Prof. Gustavo Correa Mirapalheta)
library(tidyverse);
library(tidytext);
library(dplyr);
library(janeaustenr);
library(wordcloud);
#Vamos utilizar a obra de Jane Austen
#Como primeiro passo iremos tokenizar o texto
austen_books()
austen_books()[11:20,] #explorando o dataframe
group_by(austen_books(), book) -> austen_group; austen_group
austen_group
austen_group
mutate(austen_group, linenumber = row_number()) -> austen_mutate1;
austen_mutate1
mutate(austen_mutate1, chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE) ) ) ) -> austen_mutate2; austen_mutate2
ungroup(austen_mutate2) -> austen_ungroup; head(austen_ungroup)
unnest_tokens(austen_ungroup, word, text) -> austen_unnest; head(austen_unnest)
mutate(austen_unnest, author = "Jane Austen")->tidy_books2
dc <- scan(file="domcasmurro.txt", what = "character")
setwd(".")
dc <- scan(file="domcasmurro.txt", what = "character")
dc <- scan(file="domcasmurro.txt", what = "character")
setwd("C:/Users/logonrmlocal/Desktop/fiap-mba-big-data-data-science/Big Data Mining & Inteligência Artificial/Aula 2")
dc <- scan(file="domcasmurro.txt", what = "character")
dc[is.na(dc)] <- "NA" #corrige ambiguidade na importacao de em+a=na maiscula
dc[1:100]
dc[1:100]
#pontuacao
pontuacao<-c(",", ";", ":", ".", "!", "?", "-", "/", "[", "]", "?", "!",
"#", "`", "<asp1>", "<asp2>", "(", ")", "+", "-", "=", "$", "?")
pontuacao
#tokens
length(dc)
#palavras
length(dc[!is.element(dc,pontuacao)])
#pontuacao
length(dc[is.element(dc,pontuacao)])
table(dc[is.element(dc,pontuacao)])
pontuacao_original <- pontuacao
# Separa caracteres de pontuação e outros das palavras
# dentro do vetor de palavras
dc_antigo <- dc
dc <- f.separaelementos(dc)
f.separa.paragrafo<-function(vetor.texto)
{
lista.texto<-list()
posicao.lista<-1
tokens<-length(vetor.texto)
quebras<-c(1:tokens)[vetor.texto=="<p>"]
for (i in 1:(length(quebras)-1))
{
if (quebras[i+1]-quebras[i]>1)
{
lista.texto[[posicao.lista]]<- c(vetor.texto[(quebras[i]+1):(quebras[i+1]-1)])
posicao.lista<-posicao.lista+1
}
}
return(lista.texto)
}
################################################################################################################
# funcao perto                                                                                                 #
################################################################################################################
perto<-function(vetor.texto, foco, onde)
{
posicao<-seq(along=vetor.texto)[vetor.texto==foco]
return(as.matrix(vetor.texto[posicao+onde]))
}
################################################################################################################
# funcao kwic = key word in context                                                                            #
################################################################################################################
f.kwic<-function(vetor.texto, foco, contexto)
{
posicao<-seq(along=vetor.texto)[vetor.texto==foco]
#tratamento de exce??es
if (length(posicao)==0)
{
print("Palavra em foco nao encontrada.")
return()
}
if (contexto<2)
{
esquerda<-vector(mode="character")
direita <-vector(mode="character")
eixo<-vector(mode="character")
eixo[1:length(posicao)]<-foco
for (i in (seq(along=posicao)))
{
esquerda[i]<-paste(vetor.texto[posicao[i]-1], collapse=" ")
direita[i]<-paste(vetor.texto[posicao[i]+1], collapse=" ")
}
saida<-cbind(as.data.frame(esquerda),as.data.frame(eixo),as.data.frame(direita))
names(saida)<-c("esq","foco","dir")
return(saida)
}
if (posicao[1]<=contexto)
{
print("Primeira ocorrencia anterior ao contexto desejado.")#programador sem tempo...
return()
}
#casos normais
esquerda<-vector(mode="character")
direita <-vector(mode="character")
eixo<-vector(mode="character")
eixo[1:length(posicao)]<-foco
for (i in (seq(along=posicao)))
{
esquerda[i]<-paste(vetor.texto[(posicao[i]-contexto):(posicao[i]-1)], collapse=" ")
direita[i]<-paste(vetor.texto[(posicao[i]+1):(posicao[i]+contexto)], collapse=" ")
}
saida<-cbind(as.data.frame(esquerda),as.data.frame(eixo),as.data.frame(direita))
names(saida)<-c("esq","foco","dir")
return(saida)
}
################################################################################################################
## fun??o separaelementos                                                                                     ##
################################################################################################################
f.separaelementos <- function(texto)
{
v.ret <- vector(mode="numeric")
if (length(texto)==0) return(v.ret)
v.ret <- unlist(strsplit(as.vector(texto)," "))
v.ret <- gsub("\\["," \\[ ",v.ret)                  # simbolo [
v.ret <- gsub("\\]"," \\] ",v.ret)                  # simbolo ]
v.ret <- gsub("([?!:;,~\\.^$%&*+=-])"," \\1 ",v.ret)
v.ret <- gsub("\\("," \\( ",v.ret)                  # simbolo (
v.ret <- gsub("\\)"," \\) ",v.ret)                  # simbolo )
v.ret <- gsub("\\#"," \\# ",v.ret)                  # simbolo #
v.ret <- gsub("\\`"," \\` ",v.ret)                  # simbolo `
v.ret <- gsub("\""," <asp2> ",v.ret)                # aspas duplas
v.ret <- gsub("\'"," <asp1> ",v.ret)                # aspas simples
v.ret <- gsub("\t"," ",v.ret)
v.ret <- gsub("\n"," ",v.ret)
v.ret <- unlist(strsplit(as.vector(v.ret)," "))
v.ret <- v.ret[nchar(v.ret) > 0]
# Aglutina elementos estruturais
v.ret <- f.trocaelemento(v.ret,c("i",".","e","."),"i.e.",FALSE)
v.ret <- f.trocaelemento(v.ret,c("e",".","g","."),"e.g.",FALSE)
v.ret <- f.trocaelemento(v.ret,c("<asp1>","d"),"'d",FALSE)
v.ret <- f.trocaelemento(v.ret,c("<asp1>","s"),"'s",FALSE)
v.ret <- f.trocaelemento(v.ret,c("(","c",")"),"(c)",FALSE)
v.ret <- f.trocaelemento(v.ret,c("(","r",")"),"(r)",FALSE)
v.ret <- f.trocaelemento(v.ret,c("http",":","/","/"),"http://",FALSE)
return (v.ret[nchar(v.ret) > 0])
}
################################################################################################################
## fun??o trocaelemento                                                                                       ##
################################################################################################################
# Troca a ocorr?ncia de um elemento ou mais (lista.antigo) por outro
f.trocaelemento <- function(vetor.texto,lista.antigo,texto.novo,IGNORAMAIUSCULAS)
{
tamelem <- length(lista.antigo)
KN.elemento <- f.procuraexpressao(vetor.texto,lista.antigo,IGNORAMAIUSCULAS)
for (i in KN.elemento)
{
vetor.texto[i] <- texto.novo
if (tamelem > 1)
vetor.texto[(i+1):(i+tamelem-1)] <- ""
}
return (vetor.texto[nchar(vetor.texto) > 0])
}
################################################################################################################
## fun??o procuraexpressao                                                                                   ##
################################################################################################################
f.procuraexpressao <- function(vetor.texto, vetor.expressao, IGNORAMAIUSCULAS)
{
if (IGNORAMAIUSCULAS)
posini<-(1:length(vetor.texto))[tolower(vetor.texto)==tolower(vetor.expressao[1])]
else
posini<-(1:length(vetor.texto))[vetor.texto==(vetor.expressao[1])]
if (length(posini)==0) return(posini)
tamanho<-length(vetor.expressao)
expressao <- paste(vetor.expressao, collapse=" ")
pos<-vector(mode="numeric")
for (i in posini)
{
expri <- paste(vetor.texto[i:min(i+tamanho-1,length(vetor.texto))], collapse=" ")
if (IGNORAMAIUSCULAS)
{ if (tolower(expri)==tolower(expressao)) pos <- c(pos,i) }
else
{ if (expri==expressao) pos <- c(pos,i) }
}
return(pos)
}
dc <- f.separaelementos(dc)
#tokens
length(dc)
#palavras
length(dc[!is.element(dc,pontuacao)])
#pontuacao
length(dc[is.element(dc,pontuacao)])
table(dc[is.element(dc,pontuacao)])
#palavras
palavras <- dc[!is.element(dc,pontuacao)]
table(palavras)->temp
palavras<-dimnames(temp)[[1]]
frequencias<-as.vector(temp)
rm(temp)
palavras[frequencias>100]
frequencias
frequencias[frequencias>100]
palavras[frequencias>100]
palavras
estruturais<-c( "a",   "A",       "agora",   "ainda",   "algum",   "alguma",  "algumas", "alguns", "antes",
"ao",      "Ao",      "aos",     "aqui",    "as",      "As",      "Às",      "assim",   "Assim",   "até",
"bem",     "CAPÍTULO","com",     "comigo",  "como",    "cousa",   "creio",   "D",       "da",      "dar",
"das",     "dava",    "de",      "dela",     "dele",    "dentro",  "depois",  "depressa", "deu",    "disse",
"dizer",   "dizia",   "do",      "dos",     "dous",    "duas",    "e",       "E",       "é",       "à",
"ela",     "ele",     "eles",    "em",      "Em",      "ent?o",   "Ent?o",   "entrar",  "entre",   "era",
"Era",     "eram",    "esta",    "está",    "estar",   "estava",  "este",    "eu",      "Eu",      "falar",
"fazer",   "fez",     "fim",     "foi",     "Foi",     "fora",    "fosse",   "fui",     "gente",   "grande",
"há",      "havia",   "ia",      "ir",      "isso",    "isto",    "já",      "Já",      "la",      "lá",
"lhe",     "lo",      "logo",    "mais",    "mal",     "mas",     "Mas",     "me",      "meio",    "melhor",
"menos",   "mesma",   "mesmo",   "meu",     "meus",    "mim",     "minha",   "muito",   "na",      "nada",
"não",     "Não",     "nas",     "nem",     "no",      "No",      "nos",     "nós",     "nossa",   "o",
"O",       "os",      "Os",      "ou",      "outra",   "outras",  "outro",   "outros",  "para",    "pela",
"pelo",    "pode",    "podia",   "Pois",    "por",     "porque",  "pouco",   "primeira","primeiro","quando",
"Quando",  "que",     "Que",     "queria",  "quis",    "são",     "se",      "Se",      "sei",     "sem",
"sempre",  "senhor",  "senhora", "ser",     "seu",     "seus",    "si",      "só",      "sua",     "tal",
"também",  "Também",  "tanto",   "tão",     "tarde",   "tem",     "ter",     "tinha",   "toda",    "todas",
"todo",    "todos",   "tudo",    "um",      "Um",      "uma",     "Uma",     "veio",    "vez",     "vezes",
"vi")
temp
palavras
palavrasfinal <- dc[!is.element(dc,c(pontuacao,estruturais))]
table(palavrasfinal)->temp
palavrasfinal<-dimnames(temp)[[1]]
frequenciasfinal<-as.vector(temp)
rm(temp)
palavrasfinal[frequenciasfinal>100]
frequenciasfinal[frequenciasfinal>100]
palavras[c(1:length(frequencias))[frequencias[!is.element(palavras,estruturais)]>200]]
palavras[frequencias==3]
f.kwic(dc,"favor",1)
f.kwic(dc,"favor",3)
f.kwic(dc,"favor",5)
f.kwic(dc,"favor",10)
f.kwic(dc,"sangue",3)
f.kwic(dc,"sangue",10)
f.kwic(dc,"favor",1)
## FIAP - 1S2020
## Data mining
## Prof. André Insardi
## (adaptado de material de Prof. Gustavo Correa Mirapalheta)
library(tidyverse);
library(tidytext);
library(dplyr);
library(janeaustenr);
library(wordcloud);
#Vamos utilizar a obra de Jane Austen
#Como primeiro passo iremos tokenizar o texto
austen_books()
austen_books()[11:20,] #explorando o dataframe
group_by(austen_books(), book) -> austen_group;
austen_group
mutate(austen_group, linenumber = row_number()) -> austen_mutate1;
austen_mutate1
mutate(austen_mutate1, chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE) ) ) ) -> austen_mutate2; austen_mutate2
ungroup(austen_mutate2) -> austen_ungroup; head(austen_ungroup)
unnest_tokens(austen_ungroup, word, text) -> austen_unnest; head(austen_unnest)
mutate(austen_unnest, author = "Jane Austen")->tidy_books2
## Wordclouds - Palavras + comuns em Jane Austen
#install.packages("wordcloud")
######### DESENHA NUVEM########
library(wordcloud);
anti_join(tidy_books2, stop_words) -> books_antijoin
count(books_antijoin, word) -> books_count
with(books_count, wordcloud(word, n, max.words=100)) -> books_cloud
library(tidyverse)
library(tidytext)
library(dplyr)
library(janeaustenr)
head(tidytext::sentiments)
head(tidytext::sentiments)
install.packages("gutenbergr")
head(tidytext::sentiments)
get_sentiments("bing") %>% head()
get_sentiments("bing")
austen_books()
austen_books()[11:20,] #explorando o dataframe
group_by(austen_books(), book) -> austen_group; austen_group
austen_books()[11:20,0:20] #explorando o dataframe
austen_books()[11:20,:20] #explorando o dataframe
1group_by(austen_books(), book) -> austen_group; austen_group
austen_books()[11:20,1:20] #explorando o dataframe
austen_books()[11:20,1:20] #explorando o dataframe
austen_books()[11:20,1] #explorando o dataframe
austen_books()[11:20,] #explorando o dataframe
austen_books()[11:20,1,2] #explorando o dataframe
austen_books()[11:20,1:2] #explorando o dataframe
austen_books()[11:20,] #explorando o dataframe
group_by(austen_books(), book) -> austen_group; austen_group
austen_group
austen_books()
View(austen_group)
View(austen_group)
mutate(austen_group, linenumber = row_number()) -> austen_mutate1; austen_mutate1
View(austen_mutate1)
View(austen_mutate1)
View(austen_mutate1)
View(austen_mutate1)
mutate(austen_mutate1, chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE) ) ) ) -> austen_mutate2; austen_mutate2
View(austen_mutate2)
View(austen_mutate2)
View(austen_mutate2)
View(austen_mutate2)
ungroup(austen_mutate2) -> austen_ungroup; head(austen_ungroup)
View(austen_mutate2)
View(austen_ungroup)
View(austen_ungroup)
ungroup(austen_mutate2) -> austen_ungroup; head(austen_ungroup)
#- Em seguida tokenizamos o dataframe, uma palavra por linha
#tokenização
unnest_tokens(austen_ungroup, word, text) -> austen_unnest; head(austen_unnest)
View(austen_ungroup)
View(austen_unnest)
## An?lise de Sentimento: *joy* em *Emma*
#tirar caracteres especiais
mutate(austen_unnest, word = str_extract(word,
"[a-z']+")) -> austen_unnest; austen_unnest
#- Por precau??o vamos filtrar tamb?m os NAs
filter(austen_unnest, !is.na(word)) -> austen_unnest; austen_unnest
inner_join(austen_unnest, get_sentiments("bing")) -> tidy_join; tidy_join
count(tidy_join, book, index = linenumber %/% 80, sentiment) -> tidy_count; tidy_count
inner_join(austen_unnest, get_sentiments("bing")) -> tidy_join; tidy_join
View(tidy_join)
View(tidy_join)
count(tidy_join, book, index = linenumber %/% 80, sentiment) -> tidy_count; tidy_count
count(tidy_join, book, index = linenumber, sentiment) -> tidy_count; tidy_count
count(tidy_join, book, index = linenumber %/% 80, sentiment) -> tidy_count; tidy_count
View(tidy_count)
View(tidy_count)
View(austen_ungroup)
count(tidy_join, book, index = chapter, sentiment) -> tidy_chapter; tidy_chapter
View(tidy_chapter)
View(tidy_chapter)
View(tidy_chapter)
View(tidy_count)
spread(tidy_count, sentiment, n, fill = 0) -> tidy_spread; tidy_spread
View(tidy_spread)
mutate(tidy_spread, sentiment = positive - negative) -> tidy_mutate; tidy_mutate
View(tidy_spread)
View(tidy_mutate)
tidy_mutate -> janeaustensentiment; janeaustensentiment
View(janeaustensentiment)
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) -> jane_plot; jane_plot
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) -> jane_plot; jane_plot
jane_plot + geom_col(show.legend = FALSE) -> jane_col; jane_col
jane_col + facet_wrap(~book, ncol = 2, scales = "free_x")
jane_col + facet_wrap(~book, ncol = 2, scales = "free_x")
jane_col + facet_wrap(~book, ncol = 1, scales = "free_x")
jane_col + facet_wrap(~book, ncol = 1, scales = "free_x")
jane_col + facet_wrap(~book, ncol = 2, scales = "free_x")
jane_plot + geom_col(show.legend = FALSE) -> jane_col; jane_col
## Wordclouds
library(gutenbergr)
bronte <- gutenberg_download(c(1260, 768, 969, 9182, 767))
tidy_bronte <- bronte %>%
unnest_tokens(word, text) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
anti_join(stop_words, by=c("word"="word"))
View(tidy_bronte)
gutenbergr
View(bronte)
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
mutate(tidy_bronte, author = "Bront? Sisters")->tidy_bronte2
mutate(tidy_bronte, author = "Bront? Sisters")->tidy_bronte2
mutate(tidy_hgwells, author = "H.G. Wells")->tidy_hgwells2
mutate(austen_unnest, author = "Jane Austen")->tidy_books2
tidy_books2
